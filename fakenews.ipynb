{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab5e2519-5386-4e34-899b-9ce29d907591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import the Necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f1b99370-d224-454e-9ae2-cef1bc8c2bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True News Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21417 entries, 0 to 21416\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    21417 non-null  object\n",
      " 1   text     21417 non-null  object\n",
      " 2   subject  21417 non-null  object\n",
      " 3   date     21417 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 669.4+ KB\n",
      "None\n",
      "\n",
      "Fake News Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23481 entries, 0 to 23480\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    23481 non-null  object\n",
      " 1   text     23481 non-null  object\n",
      " 2   subject  23481 non-null  object\n",
      " 3   date     23481 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 733.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  \n",
       "0  December 31, 2017  \n",
       "1  December 31, 2017  \n",
       "2  December 30, 2017  \n",
       "3  December 29, 2017  \n",
       "4  December 25, 2017  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV files\n",
    "true_news = pd.read_csv(\"C:\\\\Users\\\\MAYANK SAXENA\\\\Desktop\\\\fake news detector dataset\\\\true\\\\True.csv\")\n",
    "fake_news = pd.read_csv(\"C:\\\\Users\\\\MAYANK SAXENA\\\\Desktop\\\\fake news detector dataset\\\\fake\\\\Fake.csv\")\n",
    "\n",
    "# Explore the datasets\n",
    "print(\"True News Dataset Info:\")\n",
    "print(true_news.info())\n",
    "print(\"\\nFake News Dataset Info:\")\n",
    "print(fake_news.info())\n",
    "\n",
    "# Check the first few rows of each dataset\n",
    "true_news.head()\n",
    "fake_news.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b986f72e-619a-43c1-8e3f-84698ee9518c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title      0\n",
      "text       0\n",
      "subject    0\n",
      "date       0\n",
      "label      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Data Preprocessing\n",
    "\n",
    "# Add a label column to both datasets\n",
    "true_news['label'] = 1\n",
    "fake_news['label'] = 0\n",
    "\n",
    "# Concatenate the datasets\n",
    "news_data = pd.concat([true_news, fake_news], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Check for missing values\n",
    "print(news_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17538d9c-05b7-4df1-ab95-75565994e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Text Cleaning\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords if you haven't already\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Function to clean the text data\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])\n",
    "    return text\n",
    "\n",
    "# Apply text cleaning to the dataset\n",
    "news_data['cleaned_text'] = news_data['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838e8302-6c61-4524-8ff1-75f874efaf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Exploratory Data Analysis (EDA)\n",
    "# Count of true and fake news\n",
    "sns.countplot(news_data['label'])\n",
    "plt.title('Distribution of True and Fake News')\n",
    "plt.show()\n",
    "\n",
    "# Check the length of the articles\n",
    "news_data['text_length'] = news_data['text'].apply(len)\n",
    "sns.histplot(news_data['text_length'], bins=50)\n",
    "plt.title('Distribution of Article Lengths')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a56149-72e2-4d6d-a56f-00915ee3c6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6: Feature Extraction\n",
    "# Use TfidfVectorizer to convert the cleaned text data into numerical features suitable for model training.\n",
    "\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "\n",
    "# Fit and transform the data\n",
    "X = vectorizer.fit_transform(news_data['cleaned_text'])\n",
    "\n",
    "# Extract the target labels\n",
    "y = news_data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8a5902-f94a-48cb-9a6e-e76fc7750427",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 7: Train-Test Split\n",
    "#Split the data into training and testing sets to evaluate your model's performance.\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the size of the training and testing sets\n",
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e821006a-afad-49d4-8a86-cf67609f4bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Model Building\n",
    "# Choose a classification algorithm (e.g., Logistic Regression) to train your model.\n",
    "# Initialize the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ede90ba-02f7-4a22-8f6e-47f5348b7bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Model Evaluation\n",
    "# Evaluate the model's performance on the test set using accuracy, confusion matrix, and classification report.\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20aa408-2a6f-451d-a6b5-dcdf81e8abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Fine-Tuning\n",
    "# You can experiment with different machine learning algorithms (e.g., Random Forest, Naive Bayes, SVM), hyperparameter tuning, and feature engineering to improve the model's performance.\n",
    "\n",
    "# python\n",
    "# Example: Trying a Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(f'Random Forest Accuracy: {accuracy_score(y_test, y_pred_rf)*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d3bdbf-92f6-4e31-83df-872530537f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Save the Model\n",
    "# Once you are satisfied with the model performance, save the trained model for future use.\n",
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'fake_news_detector.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8686abd0-a7b1-4347-a558-1be015f62382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
